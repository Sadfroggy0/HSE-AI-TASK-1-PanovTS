{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhoT4D6cmfzR"
   },
   "source": [
    "#### Копируем репозиторий и устанавливаем зависимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zfwiiy5kg1fc",
    "outputId": "d0901db2-e839-4bbb-d689-52bc74fdc80a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ai4se-hse-course-24-25'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 5 (from 1)\u001b[K\n",
      "Receiving objects: 100% (12/12), 4.42 KiB | 4.42 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ai4se-course/ai4se-hse-course-24-25.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbsjgQGLg1dX"
   },
   "outputs": [],
   "source": [
    "!pip3 install -r /content/ai4se-hse-course-24-25/01-toxic-review-classification/requirements.txt \\\n",
    "              -r /content/ai4se-hse-course-24-25/01-toxic-review-classification/requirements_dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnk4FLg1MHJF"
   },
   "source": [
    "#### Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_wJfjpVDptH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCrDler9M2pn"
   },
   "source": [
    "#### Объявляем собственный класс для набора данных\n",
    "Класс принимает 4 параметра и преобразует данные в форму, удобную для RoBERT:\n",
    "* тексты\n",
    "* метки\n",
    "* токенизатор\n",
    "* максимальная длина для токенов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96QjTYaBM1z1"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySx-Kgb3MJwE"
   },
   "source": [
    "#### Объявляем функцию для вычисления метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VM6wDMVOdHxE"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)  # Получаем предсказания\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')  # Используем weighted для многоклассовой классификации\n",
    "    acc = accuracy_score(labels, preds)  # Вычисляем accuracy\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BtUPN31t-HL"
   },
   "source": [
    "#### Немного предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWCNc1OCDOor"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('code-review-dataset-full.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znY_frsBMbNu"
   },
   "source": [
    "1. удаляем пустые ячейки\n",
    "2. удаляем из текстов ссылки\n",
    "3. удаляем небуквенные символы\n",
    "4. удаляем дубликаты, тк они могли появиться после преобразований"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p5DtM6TumsFA"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.rename(columns={'is_toxic':'label'}, inplace=True)\n",
    "\n",
    "url_pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
    "\n",
    "# убираем ссылки, символы\n",
    "df['text'] =  df['message'].apply(lambda sent: re.sub(url_pattern, \"\", sent))\\\n",
    "                               .apply(lambda sent: re.sub('[^a-zA-Z]', ' ', sent))\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zohXzEuPOVPN"
   },
   "source": [
    "#### Объявляем токенизатор и модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrBUvv5xFE3y"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(f\"FacebookAI/{MODEL_NAME}\", clean_up_tokenization_spaces=True)\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model_roberta = RobertaForSequenceClassification.from_pretrained(f'FacebookAI/{MODEL_NAME}', num_labels=2).to(device)\n",
    "\n",
    "MAX_LENGTH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf6ckCh2OZj6"
   },
   "source": [
    "#### Подготовка данных\n",
    "1. Разбиваем данные на тренировачную, валидационную и тестовую\n",
    "2. Объявляем для каждой выборки свой датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPp4KfLAmJ34"
   },
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(df['text'], df['label'],\n",
    "                                                  test_size=.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,\n",
    "                                                    test_size=.25,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCz7vOnm0Yz9"
   },
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    X_train.to_list(),\n",
    "    y_train.to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "eval_dataset = CustomDataset(\n",
    "    X_eval.to_list(),\n",
    "    y_eval.to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    X_test.to_list(),\n",
    "    y_test.to_list(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=MAX_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sPgCH_fyula"
   },
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'eval': eval_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRVpnK4WOtg6"
   },
   "source": [
    "#### Объявляем параметры для тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13ue1O06g0cR"
   },
   "outputs": [],
   "source": [
    "TASK = 'toxic_classification'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir='./logs',\n",
    "    output_dir='./results'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH63jOZhOyRR"
   },
   "source": [
    "#### Объявляем класс-тренер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20FSoBs6g0XH"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_roberta,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['eval'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLTks4V8O5F1"
   },
   "source": [
    "#### Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "j-COS7N1g0Up",
    "outputId": "9ddea4a1-8f01-4bb0-8d57-ed3e5bf2125f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241103_095515-u5tpjwx8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tim-panov1337-hse/huggingface/runs/u5tpjwx8' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/tim-panov1337-hse/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tim-panov1337-hse/huggingface' target=\"_blank\">https://wandb.ai/tim-panov1337-hse/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tim-panov1337-hse/huggingface/runs/u5tpjwx8' target=\"_blank\">https://wandb.ai/tim-panov1337-hse/huggingface/runs/u5tpjwx8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2420' max='2420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2420/2420 31:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.353100</td>\n",
       "      <td>0.260611</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.914946</td>\n",
       "      <td>0.916699</td>\n",
       "      <td>0.915574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.317823</td>\n",
       "      <td>0.908175</td>\n",
       "      <td>0.904842</td>\n",
       "      <td>0.908175</td>\n",
       "      <td>0.905197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.323332</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.906526</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.897533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.299220</td>\n",
       "      <td>0.911275</td>\n",
       "      <td>0.908900</td>\n",
       "      <td>0.911275</td>\n",
       "      <td>0.906128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.299339</td>\n",
       "      <td>0.915537</td>\n",
       "      <td>0.913124</td>\n",
       "      <td>0.915537</td>\n",
       "      <td>0.911378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.295437</td>\n",
       "      <td>0.912824</td>\n",
       "      <td>0.910430</td>\n",
       "      <td>0.912824</td>\n",
       "      <td>0.908042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.295684</td>\n",
       "      <td>0.913212</td>\n",
       "      <td>0.910763</td>\n",
       "      <td>0.913212</td>\n",
       "      <td>0.908585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.290484</td>\n",
       "      <td>0.915537</td>\n",
       "      <td>0.912761</td>\n",
       "      <td>0.915537</td>\n",
       "      <td>0.912206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.301802</td>\n",
       "      <td>0.908563</td>\n",
       "      <td>0.906117</td>\n",
       "      <td>0.908563</td>\n",
       "      <td>0.906915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220400</td>\n",
       "      <td>0.305341</td>\n",
       "      <td>0.907013</td>\n",
       "      <td>0.905228</td>\n",
       "      <td>0.907013</td>\n",
       "      <td>0.905944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 56s, sys: 29.1 s, total: 30min 25s\n",
      "Wall time: 36min 31s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2420, training_loss=0.26592264254231096, metrics={'train_runtime': 2188.9735, 'train_samples_per_second': 35.368, 'train_steps_per_second': 1.106, 'total_flos': 5092514476492800.0, 'train_loss': 0.26592264254231096, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U90QIsQ3vQos"
   },
   "source": [
    "#### Сохраняем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjS3pBGovHOC"
   },
   "outputs": [],
   "source": [
    "model_parameters = model_roberta.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoxkfFJZg0RU",
    "outputId": "3272dfde-a283-41ab-9cf4-828d85f1cf4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_roberta/tokenizer_config.json',\n",
       " './fine_tuned_roberta/special_tokens_map.json',\n",
       " './fine_tuned_roberta/vocab.json',\n",
       " './fine_tuned_roberta/merges.txt',\n",
       " './fine_tuned_roberta/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_roberta.save_pretrained('./fine_tuned_roberta')\n",
    "tokenizer.save_pretrained('./fine_tuned_roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHzU34h654KH"
   },
   "source": [
    "#### Загрузим pre-trained модель и проведём оценку на тестовом наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCsDbiYU54DC"
   },
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('./fine_tuned_roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LftN4Y1S537N",
    "outputId": "f4d24388-1ec7-4c4b-be78-ae319865ff5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 1s, sys: 1min 35s, total: 10min 37s\n",
      "Wall time: 10min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(batch['labels'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7UG32Kc53jL",
    "outputId": "f2262ce7-33b2-4676-e826-0b4bc6baa3d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9240604416892677, 'precision': 0.9219866435422849, 'recall': 0.9240604416892677, 'f1': 0.9223984636774184}\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')  # Используем weighted для многоклассовой классификации\n",
    "acc = accuracy_score(true_labels, predictions)  # Вычисляем accuracy\n",
    "print({\n",
    "    'accuracy': acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkFhn0Vb53bG",
    "outputId": "444e5d00-79ef-4590-9346-14e2b810e3bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: fine_tuned_roberta/ (stored 0%)\n",
      "  adding: fine_tuned_roberta/code-review-dataset-full.xlsx (deflated 1%)\n",
      "  adding: fine_tuned_roberta/merges.txt (deflated 53%)\n",
      "  adding: fine_tuned_roberta/special_tokens_map.json (deflated 84%)\n",
      "  adding: fine_tuned_roberta/model.safetensors (deflated 13%)\n",
      "  adding: fine_tuned_roberta/config.json (deflated 50%)\n",
      "  adding: fine_tuned_roberta/vocab.json (deflated 68%)\n",
      "  adding: fine_tuned_roberta/tokenizer_config.json (deflated 76%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r RoBERTa.zip fine_tuned_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMZ_6NCm53TL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQ4RR6385s0h"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
